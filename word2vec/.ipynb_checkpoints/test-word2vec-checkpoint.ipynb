{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Test (Word2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考リンク https://qiita.com/makaishi2/items/63b7986f6da93dc55edd\n",
    "まずは「三四郎」の冒頭部分を出しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "# ファイル読込み、内部表現化\n",
    "f = codecs.open('sanshiro.txt', \"r\", \"sjis\")\n",
    "text = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイル整形\n",
    "import re\n",
    "# ヘッダ部分の除去\n",
    "# text = re.split('\\-{5,}',text)[2]\n",
    "# フッタ部分の除去\n",
    "text = re.split('底本：',text)[0]\n",
    "# | の除去\n",
    "text = text.replace('|', '')\n",
    "# ルビの削除\n",
    "text = re.sub('《.+?》', '', text)\n",
    "# 入力注の削除\n",
    "text = re.sub('［＃.+?］', '',text)\n",
    "# 空行の削除\n",
    "text = re.sub('\\n\\n', '\\n', text) \n",
    "text = re.sub('\\r', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "一\n",
      "　うとうととして目がさめると女はいつのまにか、隣のじいさんと話を始めている。このじいさんはたしかに前の前の駅から乗ったいなか者である。発車まぎわに頓狂な声を出して駆け込んで来て、いきなり肌をぬい\n",
      "\n",
      "\n",
      "の評に取りかかる。与次郎だけが三四郎のそばへ来た。\n",
      "「どうだ森の女は」\n",
      "「森の女という題が悪い」\n",
      "「じゃ、なんとすればよいんだ」\n",
      "　三四郎はなんとも答えなかった。ただ口の中で迷羊、迷羊と繰り返した。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 整形結果確認\n",
    "\n",
    "# 頭の100文字の表示 \n",
    "print(text[:100])\n",
    "# 見やすくするため、空行 \n",
    "print()\n",
    "print()\n",
    "# 後ろの100文字の表示 \n",
    "print(text[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に Janome を使って見ましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Janomeのロード\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "# Tokenneizerインスタンスの生成 \n",
    "t = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "三四郎\n",
      "京都\n",
      "ちょっと\n",
      "用\n",
      "ある\n",
      "降りる\n",
      "ついで\n"
     ]
    }
   ],
   "source": [
    "# テキストを引数として、形態素解析の結果、名詞・動詞原型のみを配列で抽出する関数を定義 \n",
    "def extract_words(text):\n",
    "    tokens = t.tokenize(text)\n",
    "    return [token.base_form for token in tokens \n",
    "        if token.part_of_speech.split(',')[0] in['名詞', '動詞']]\n",
    "\n",
    "#  関数テスト\n",
    "ret = extract_words('三四郎は京都でちょっと用があって降りたついでに。')\n",
    "for word in ret:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一\n",
      "する\n",
      "目\n",
      "さめる\n",
      "女\n",
      "隣\n",
      "じいさん\n",
      "話\n",
      "始める\n",
      "いる\n"
     ]
    }
   ],
   "source": [
    "# 全体のテキストを句点('。')で区切った配列にする。 \n",
    "sentences = text.split('。')\n",
    "# それぞれの文章を単語リストに変換(処理に数分かかります)\n",
    "word_list = [extract_words(sentence) for sentence in sentences]\n",
    "\n",
    "# 結果の一部を確認 \n",
    "for word in word_list[0]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vecライブラリのロード\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# size: 圧縮次元数\n",
    "# min_count: 出現頻度の低いものをカットする\n",
    "# window: 前後の単語を拾う際の窓の広さを決める\n",
    "# iter: 機械学習の繰り返し回数(デフォルト:5)十分学習できていないときにこの値を調整する\n",
    "# model.wv.most_similarの結果が1に近いものばかりで、model.dict['wv']のベクトル値が小さい値ばかりの \n",
    "# ときは、学習回数が少ないと考えられます。\n",
    "# その場合、iterの値を大きくして、再度学習を行います。\n",
    "\n",
    "# 事前準備したword_listを使ってWord2Vecの学習実施\n",
    "model = word2vec.Word2Vec(word_list, size=100,min_count=5,window=5,iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.65313166 -0.62891906  0.17438062  0.26170734  0.13503277  0.1434436\n",
      "  0.3228045   0.16177198  0.2681557   0.20288964 -0.5050857  -0.27775013\n",
      " -0.6406938   0.26332816  0.65016234  0.16011722  0.39971462  0.21006517\n",
      "  0.22237374  0.77312905 -0.08696599 -0.08956906 -0.75035876 -0.30150267\n",
      "  0.02591058  0.75857884  0.5207765  -0.08462646  0.08198166 -0.79446936\n",
      " -0.36525548  0.24380173 -0.03011892 -0.70276207 -0.48627678  0.58974975\n",
      "  0.51893663 -0.26492783  0.3536507   0.24789363 -0.43629184 -0.06122503\n",
      " -0.03264514  0.2280395   0.28010875  1.06901    -0.48890734 -0.1555945\n",
      "  0.82734746 -0.00135017 -0.18063134 -0.13531289 -0.26069164  0.10685145\n",
      "  0.78156453  0.46627632 -0.07300753 -0.35923982  0.00810226 -0.36684614\n",
      " -0.7153586   0.5566864  -0.09397646 -0.80985737 -0.32292515 -0.2210996\n",
      "  0.7335055  -0.486771   -0.21325512  0.60944533  0.31590056 -0.09091179\n",
      "  0.03709435  0.44146886  0.42885622 -0.47714093  0.6710077   0.04712195\n",
      "  0.3305971  -0.24903543 -0.46706665  0.2170919  -0.17846929  0.872931\n",
      " -0.39442977 -0.23426591  0.4017619   0.13326424 -0.08228578  0.7605912\n",
      " -0.06115758  0.0474966  -0.01185337  0.2185944  -0.6958353  -0.8859576\n",
      "  0.095071    0.32504845 -0.39188835 -0.66788757]\n"
     ]
    }
   ],
   "source": [
    "# 結果の確認1\n",
    "# 一つ一つの単語は100次元のベクトルになっています。 \n",
    "# 「世間」のベクトル値を確認します。\n",
    "print(model.__dict__['wv']['世間'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "聞こえる 0.6189125776290894\n",
      "自己 0.5277218222618103\n",
      "堪える 0.5241377353668213\n",
      "喝采 0.5240006446838379\n",
      "酔う 0.5154030919075012\n",
      "決心 0.5103549361228943\n",
      "外国 0.5021237134933472\n",
      "社会 0.486386775970459\n",
      "未来 0.4771953225135803\n",
      "賛成 0.46586984395980835\n"
     ]
    }
   ],
   "source": [
    "# 結果の確認2\n",
    "# 関数most_similarを使って「世間」の類似単語を調べます \n",
    "ret = model.wv.most_similar(positive=['世間']) \n",
    "for item in ret:\n",
    "    print(item[0], item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これが全て通ったらテストが完了です。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
